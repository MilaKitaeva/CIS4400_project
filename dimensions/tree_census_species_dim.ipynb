{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a81bc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade google-api-python-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74e493a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fd4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3252ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\defar\\anaconda3x\\lib\\site-packages (14.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\defar\\anaconda3x\\lib\\site-packages (from pyarrow) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed692b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: credentials in c:\\users\\defar\\anaconda3x\\lib\\site-packages (1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e23b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.exceptions import NotFound\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import credentials\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae7d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a service account key file, save the path to that file in credentials.py and import credentials\n",
    "path_to_service_account_key_file = r\"C:\\Users\\defar\\Downloads\\cis-4400-406318-e39516b8d26d.json\"\n",
    "#!pip install credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f809a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the dimension\n",
    "dimension_name = 'tree_census_species'\n",
    "\n",
    "# Set the name of the surrogate key\n",
    "surrogate_key = f\"{dimension_name}_dim_id\"\n",
    "\n",
    "# Set the name of the business key\n",
    "business_key = f'{dimension_name}_id'\n",
    "\n",
    "# Set the GCP Project, dataset and table name\n",
    "gcp_project = 'cis-4400-406318'\n",
    "bq_dataset = 'tree_census_dataset'\n",
    "table_name = f\"{dimension_name}_dimension\"\n",
    "\n",
    "# Construct the full BigQuery path to the table\n",
    "dimension_table_path = f\"{gcp_project}.{bq_dataset}.{table_name}\"\n",
    "\n",
    "# Set the path to the source data files. Use double-slash for Windows paths C:\\\\myfolder\n",
    "# For Linux use forward slashes    /home/username/python_etl\n",
    "# For Mac use forward slashes      /users/username/python_etl\n",
    "# file_source_path = 'c:\\\\Python_ETL'\n",
    "file_source_path = r\"C:\\Users\\defar\\OneDrive\\Documents\\Baruch\\2023_FALL\\CIS 4400\\Group 8\\new_york_tree_species.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3167723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    transform_data\n",
    "    Accepts a data frame\n",
    "    Performs any specific cleaning and transformation steps on the dataframe\n",
    "    Returns the modified dataframe\n",
    "    This function can be modified based on required changes\n",
    "    \"\"\"\n",
    "    # Select the columns for this dimension\n",
    "    column_list = ['species_scientific_name', 'species_common_name','fall_color', 'environmental_tolerances','location_tolerances', 'tree_size' ]\n",
    "    \n",
    "    df = df[column_list]\n",
    "    \n",
    "    df = df.rename(columns={'species_scientific_name': 'spc_latin'})\n",
    "                   \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014a456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigquery_client():\n",
    "    \"\"\"\n",
    "    create_bigquery_client\n",
    "    Creates a BigQuery client using the path to the service account key file\n",
    "    for credentials.\n",
    "    Returns the BigQuery client object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If authenticating using a service account key file, use the following code:\n",
    "        # bqclient = bigquery.Client.from_service_account_json(credentials.path_to_service_account_key_file)\n",
    "        # Google Colab authentication already completed\n",
    "        bqclient = bigquery.Client(gcp_project)\n",
    "        return bqclient\n",
    "    except Exception as err:\n",
    "        print(\"error\")\n",
    "        # os._exit(-1)\n",
    "    return bqclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e5f9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_bigquery_table(bqclient, table_path, write_disposition, df):\n",
    "    \"\"\"\n",
    "    upload_bigquery_table\n",
    "    Accepts a path to a BigQuery table, the write disposition and a dataframe\n",
    "    Loads the data into the BigQuery table from the dataframe.\n",
    "    for credentials.\n",
    "    The write disposition is either\n",
    "    write_disposition=\"WRITE_TRUNCATE\"  Erase the target data and load all new data.\n",
    "    write_disposition=\"WRITE_APPEND\"    Append to the existing table\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up a BigQuery job configuration with the write_disposition.\n",
    "        job_config = bigquery.LoadJobConfig(write_disposition=write_disposition)\n",
    "        \n",
    "        # Submit the job\n",
    "        print(type(bqclient))\n",
    "        job = bqclient.load_table_from_dataframe(df, table_path, job_config=job_config)\n",
    "        # Show the job results\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        #os._exit(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "becdad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigquery_table_exists(bqclient, table_path):\n",
    "    \"\"\"\n",
    "    bigquery_table_exists\n",
    "    Accepts a path to a BigQuery table\n",
    "    Checks if the BigQuery table exists.\n",
    "    Returns True or False\n",
    "    \"\"\"\n",
    "    try:\n",
    "        bqclient.get_table(table_path)  # Make an API request.\n",
    "        return True\n",
    "    except NotFound:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f148147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_bigquery_table(table_path, bqclient, surrogate_key):\n",
    "    \"\"\"\n",
    "    query_bigquery_table\n",
    "    Accepts a path to a BigQuery table and the name of the surrogate key\n",
    "    Queries the BigQuery table but leaves out the update_timestamp and surrogate key columns\n",
    "    Returns the dataframe\n",
    "    \"\"\"\n",
    "    bq_df = pd.DataFrame\n",
    "    sql_query = 'SELECT * EXCEPT ( update_timestamp, '+surrogate_key+') FROM `' + table_path + '`'\n",
    "    try:\n",
    "        bq_df = bqclient.query(sql_query).to_dataframe()\n",
    "    except Exception as err:\n",
    "        print(\"error\")\n",
    "    return bq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9eeae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_surrogate_key(df, dimension_name='tree_census_species', offset=1):\n",
    "    \"\"\"\n",
    "    add_surrogate_key\n",
    "    Accepts a data frame and inserts an integer identifier as the first column\n",
    "    Returns the modified dataframe\n",
    "    \"\"\"\n",
    "    # Reset the index to count from 0\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # Add the new surrogate key starting from offset\n",
    "    df.insert(0, dimension_name+'_dim_id', df.index+offset)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "459ce232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_new_table(bqclient, dimension_table_path, dimension_name, df):\n",
    "    \"\"\"\n",
    "    build_new_table\n",
    "    Accepts a path to a dimensional table, the dimension name and a data frame\n",
    "    Add the surrogate key and a record timestamp to the data frame\n",
    "    Inserts the contents of the dataframe to the dimensional table.\n",
    "    \"\"\"\n",
    "    # Add a surrogate key\n",
    "    df = add_surrogate_key(df, dimension_name, 1)\n",
    "    # Add the update timestamp\n",
    "    # Upload the dataframe to the BigQuery table\n",
    "    upload_bigquery_table(bqclient, dimension_table_path, \"WRITE_TRUNCATE\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5be1b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'google.cloud.bigquery.client.Client'>\n"
     ]
    }
   ],
   "source": [
    "# Program main\n",
    "# Load the CSV File into a dataframe\n",
    "# Transform the Dataframe\n",
    "# Create a BigQuery client\n",
    "# See if the target dimension table exists\n",
    "#    If not exists, load the data into a new table\n",
    "#    If exists, insert new records into the table\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.DataFrame\n",
    "    # Load in the data file\n",
    "    with open(file_source_path) as data:\n",
    "            df = pd.read_csv(data)\n",
    "        # Set all of the column names to lower case letters\n",
    "    df = df.rename(columns=str.lower)\n",
    "        \n",
    "        \n",
    "    #df = load_csv_data_file(file_source_path, \"my_311_data_WaterQuality.csv\", df)\n",
    "    # Transform the data\n",
    "    df = transform_data(df)\n",
    "    # Create the BigQuery Client\n",
    "    # setup enviroment parameters to connect to BQ project\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path_to_service_account_key_file\n",
    "\n",
    "    # Construct a BigQuery client object\n",
    "    bqclient = bigquery.Client()\n",
    "\n",
    "    # See if the target dimensional table exists\n",
    "    target_table_exists = bigquery_table_exists(bqclient, dimension_table_path  )\n",
    "\n",
    "    # If the target dimension table does not exist, load all of the data into a new table\n",
    "    if not target_table_exists:\n",
    "        build_new_table( bqclient, dimension_table_path, dimension_name, df)\n",
    "    # If the target table exists, then perform an incremental load\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c59ce7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_census_species_dim_id</th>\n",
       "      <th>spc_latin</th>\n",
       "      <th>species_common_name</th>\n",
       "      <th>fall_color</th>\n",
       "      <th>environmental_tolerances</th>\n",
       "      <th>location_tolerances</th>\n",
       "      <th>tree_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ginkgo biloba</td>\n",
       "      <td>Ginkgo</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Salt Drought High Wind Pollution and High pH T...</td>\n",
       "      <td>Median Tree Narrow Growing Space</td>\n",
       "      <td>Large (Mature Height &gt; 50 ft)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Quercus spp. 'Fastigiata'</td>\n",
       "      <td>Fastigiata Oak</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>none</td>\n",
       "      <td>Median Tree Narrow Growing Space</td>\n",
       "      <td>Large (Mature Height &gt; 50 ft)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Liquidambar styraciflua</td>\n",
       "      <td>Sweetgum</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Wet Site Tolerant</td>\n",
       "      <td>none</td>\n",
       "      <td>Large (Mature Height &gt; 50 ft)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Metasequoia glyptostroboides</td>\n",
       "      <td>Dawn Redwood</td>\n",
       "      <td>Orange/Brown</td>\n",
       "      <td>Wet Site Drought High pH Tolerant</td>\n",
       "      <td>Median Tree Narrow Growing Space</td>\n",
       "      <td>Large (Mature Height &gt; 50 ft)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Taxodium distichum</td>\n",
       "      <td>Baldcypress</td>\n",
       "      <td>Orange/Brown</td>\n",
       "      <td>Wet Site Salt and High Wind Tolerant</td>\n",
       "      <td>Median Tree Narrow Growing Space</td>\n",
       "      <td>Large (Mature Height &gt; 50 ft)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tree_census_species_dim_id                     spc_latin  \\\n",
       "0                           1                 Ginkgo biloba   \n",
       "1                           2     Quercus spp. 'Fastigiata'   \n",
       "2                           3       Liquidambar styraciflua   \n",
       "3                           4  Metasequoia glyptostroboides   \n",
       "4                           5            Taxodium distichum   \n",
       "\n",
       "  species_common_name    fall_color  \\\n",
       "0              Ginkgo        Yellow   \n",
       "1      Fastigiata Oak        Maroon   \n",
       "2            Sweetgum        Yellow   \n",
       "3        Dawn Redwood  Orange/Brown   \n",
       "4         Baldcypress  Orange/Brown   \n",
       "\n",
       "                            environmental_tolerances  \\\n",
       "0  Salt Drought High Wind Pollution and High pH T...   \n",
       "1                                               none   \n",
       "2                                  Wet Site Tolerant   \n",
       "3                  Wet Site Drought High pH Tolerant   \n",
       "4               Wet Site Salt and High Wind Tolerant   \n",
       "\n",
       "                location_tolerances                      tree_size  \n",
       "0  Median Tree Narrow Growing Space  Large (Mature Height > 50 ft)  \n",
       "1  Median Tree Narrow Growing Space  Large (Mature Height > 50 ft)  \n",
       "2                              none  Large (Mature Height > 50 ft)  \n",
       "3  Median Tree Narrow Growing Space  Large (Mature Height > 50 ft)  \n",
       "4  Median Tree Narrow Growing Space  Large (Mature Height > 50 ft)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e058c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
